{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/monsterhunters/CodeUI/blob/master/comfyui_colab_V4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaaaaaaaaa"
      },
      "source": [
        "Git clone the repo and install the requirements. (ignore the pip errors about protobuf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bbbbbbbbbb",
        "cellView": "form",
        "outputId": "f186fd17-67d1-45db-d41f-8c681f153da7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounting Google Drive...\n",
            "/\n",
            "Mounted at /content/drive\n",
            "/content/drive/Shareddrives/Flash/HTZ/CodeUI\n",
            "/content/drive/Shareddrives/Flash/HTZ/CodeUI\n",
            "-= Updating CodeUI =-\n",
            "-= Install dependencies =-\n",
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu118, https://download.pytorch.org/whl/cu117\n",
            "Collecting xformers!=0.0.18\n",
            "  Downloading https://download.pytorch.org/whl/xformers-0.0.22.post4-cp310-cp310-manylinux2014_x86_64.whl (211.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.8/211.8 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (2.0.1+cu118)\n",
            "Collecting torchsde (from -r requirements.txt (line 2))\n",
            "  Downloading torchsde-0.2.6-py3-none-any.whl (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting einops (from -r requirements.txt (line 3))\n",
            "  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers>=4.25.1 (from -r requirements.txt (line 4))\n",
            "  Downloading transformers-4.34.0-py3-none-any.whl (7.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m78.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.0 (from -r requirements.txt (line 5))\n",
            "  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m83.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (3.8.6)\n",
            "Collecting accelerate (from -r requirements.txt (line 7))\n",
            "  Downloading accelerate-0.23.0-py3-none-any.whl (258 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.1/258.1 kB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (6.0.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (9.4.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (1.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (4.66.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (5.9.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xformers!=0.0.18) (1.23.5)\n",
            "Collecting torch (from -r requirements.txt (line 1))\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torch-2.1.0%2Bcu118-cp310-cp310-linux_x86_64.whl (2325.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 GB\u001b[0m \u001b[31m529.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (2023.6.0)\n",
            "Collecting triton==2.1.0 (from torch->-r requirements.txt (line 1))\n",
            "  Downloading https://download.pytorch.org/whl/triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting trampoline>=0.1.2 (from torchsde->-r requirements.txt (line 2))\n",
            "  Downloading trampoline-0.1.2-py3-none-any.whl (5.2 kB)\n",
            "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers>=4.25.1->-r requirements.txt (line 4))\n",
            "  Downloading huggingface_hub-0.18.0-py3-none-any.whl (301 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->-r requirements.txt (line 4)) (23.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->-r requirements.txt (line 4)) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->-r requirements.txt (line 4)) (2.31.0)\n",
            "Collecting tokenizers<0.15,>=0.14 (from transformers>=4.25.1->-r requirements.txt (line 4))\n",
            "  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m117.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->-r requirements.txt (line 6)) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->-r requirements.txt (line 6)) (3.3.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->-r requirements.txt (line 6)) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->-r requirements.txt (line 6)) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->-r requirements.txt (line 6)) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->-r requirements.txt (line 6)) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->-r requirements.txt (line 6)) (1.3.1)\n",
            "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers>=4.25.1->-r requirements.txt (line 4))\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.0->aiohttp->-r requirements.txt (line 6)) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->-r requirements.txt (line 1)) (2.1.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.25.1->-r requirements.txt (line 4)) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.25.1->-r requirements.txt (line 4)) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->-r requirements.txt (line 1)) (1.3.0)\n",
            "Installing collected packages: trampoline, triton, safetensors, einops, torch, huggingface-hub, xformers, torchsde, tokenizers, accelerate, transformers\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.0.0\n",
            "    Uninstalling triton-2.0.0:\n",
            "      Successfully uninstalled triton-2.0.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.0.1+cu118\n",
            "    Uninstalling torch-2.0.1+cu118:\n",
            "      Successfully uninstalled torch-2.0.1+cu118\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "fastai 2.7.12 requires torch<2.1,>=1.7, but you have torch 2.1.0+cu118 which is incompatible.\n",
            "torchaudio 2.0.2+cu118 requires torch==2.0.1, but you have torch 2.1.0+cu118 which is incompatible.\n",
            "torchdata 0.6.1 requires torch==2.0.1, but you have torch 2.1.0+cu118 which is incompatible.\n",
            "torchtext 0.15.2 requires torch==2.0.1, but you have torch 2.1.0+cu118 which is incompatible.\n",
            "torchvision 0.15.2+cu118 requires torch==2.0.1, but you have torch 2.1.0+cu118 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed accelerate-0.23.0 einops-0.7.0 huggingface-hub-0.17.3 safetensors-0.4.0 tokenizers-0.14.1 torch-2.1.0+cu118 torchsde-0.2.6 trampoline-0.1.2 transformers-4.34.0 triton-2.1.0 xformers-0.0.22.post4\n"
          ]
        }
      ],
      "source": [
        "#@title Environment Setup\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "OPTIONS = {}\n",
        "\n",
        "USE_GOOGLE_DRIVE = True  #@param {type:\"boolean\"}\n",
        "UPDATE_CodeUI = True  #@param {type:\"boolean\"}\n",
        "WORKSPACE = 'CodeUI'\n",
        "OPTIONS['USE_GOOGLE_DRIVE'] = USE_GOOGLE_DRIVE\n",
        "OPTIONS['UPDATE_CodeUI'] = UPDATE_CodeUI\n",
        "\n",
        "if OPTIONS['USE_GOOGLE_DRIVE']:\n",
        "    !echo \"Mounting Google Drive...\"\n",
        "    %cd /\n",
        "\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    WORKSPACE = \"/content/drive/Shareddrives/Flash/HTZ/CodeUI\"\n",
        "    %cd /content/drive/Shareddrives/Flash/HTZ/CodeUI\n",
        "\n",
        "![ ! -d $WORKSPACE ] && echo -= Initial setup ComfyUI =- && git clone https://github.com/monsterhunters/CodeUI\n",
        "%cd $WORKSPACE\n",
        "\n",
        "if OPTIONS['UPDATE_CodeUI']:\n",
        "  !echo -= Updating CodeUI =-\n",
        "  #!git pull\n",
        "\n",
        "!echo -= Install dependencies =-\n",
        "!pip install xformers!=0.0.18 -r requirements.txt --extra-index-url https://download.pytorch.org/whl/cu118 --extra-index-url https://download.pytorch.org/whl/cu117"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "hmnzbY8EMXCu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install aria2"
      ],
      "metadata": {
        "id": "Zunm9WV3UdWt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download Checkpoint\n",
        "#@markdown Click to show available model to download\n",
        "\n",
        "\n",
        "import os\n",
        "import requests\n",
        "from IPython.display import display, HTML\n",
        "import json\n",
        "from ipywidgets import widgets\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# Google Sheets endpoint URL\n",
        "url = \"https://sheets.googleapis.com/v4/spreadsheets/1zhDyqMIqqaDTZipJ0oz9gidHNZZchvurXeCZ_mteVas/values/checkpoint\"\n",
        "url2 = \"https://sheets.googleapis.com/v4/spreadsheets/1zhDyqMIqqaDTZipJ0oz9gidHNZZchvurXeCZ_mteVas/values/lora\"\n",
        "# Get data from Google Sheets\n",
        "params = {\"key\": \"AIzaSyAaz4SVWpLhB7owPGptGdiMRMPcgqPobsw\"}  # replace YOUR_API_KEY with your actual API key\n",
        "response = requests.get(url, params=params)\n",
        "data = response.json()\n",
        "response2 = requests.get(url2, params=params)\n",
        "data2 = response2.json()\n",
        "\n",
        "# Extract the names and URLs of the models from the JSON data\n",
        "model_names = [row[0] for row in data['values'][1:]]\n",
        "model_urls = [row[1] for row in data['values'][1:]]\n",
        "model_urls_r = [row[1] for row in data['values'][1:] if row[2] == 'realistic']\n",
        "model_urls_a = [row[1] for row in data['values'][1:] if row[2] == 'anime']\n",
        "model_urls_m = [row[1] for row in data['values'][1:] if row[2] == 'mix']\n",
        "model_urls_x = [row[1] for row in data['values'][1:] if row[2] == 'Adult']\n",
        "model_urls_d = [row[1] for row in data['values'][1:] if row[2] == '2.5D']\n",
        "r_model_names = [row[0] for row in data['values'][1:] if row[2] == 'realistic']\n",
        "a_model_names = [row[0] for row in data['values'][1:] if row[2] == 'anime']\n",
        "m_model_names = [row[0] for row in data['values'][1:] if row[2] == 'mix']\n",
        "x_model_names = [row[0] for row in data['values'][1:] if row[2] == 'Adult']\n",
        "d_model_names = [row[0] for row in data['values'][1:] if row[2] == '2.5D']\n",
        "vae_models = [row[3] for row in data['values'][1:]]\n",
        "vae_models_r = [row[3] for row in data['values'][1:] if row[2] == 'realistic']\n",
        "vae_models_a = [row[3] for row in data['values'][1:] if row[2] == 'anime']\n",
        "vae_models_m = [row[3] for row in data['values'][1:] if row[2] == 'mix']\n",
        "vae_models_x = [row[3] for row in data['values'][1:] if row[2] == 'Adult']\n",
        "vae_models_d = [row[3] for row in data['values'][1:] if row[2] == '2.5D']\n",
        "\n",
        "\n",
        "\n",
        "# Create a checkbox for each model name\n",
        "checkboxes = [widgets.Checkbox(description=model_name) for model_name in model_names]\n",
        "checkboxes_r = [widgets.Checkbox(description=r_model_name) for r_model_name in r_model_names]\n",
        "checkboxes_a = [widgets.Checkbox(description=a_model_name) for a_model_name in a_model_names]\n",
        "checkboxes_m = [widgets.Checkbox(description=m_model_name) for m_model_name in m_model_names]\n",
        "checkboxes_x = [widgets.Checkbox(description=x_model_name) for x_model_name in x_model_names]\n",
        "checkboxes_d = [widgets.Checkbox(description=d_model_name) for d_model_name in d_model_names]\n",
        "\n",
        "\n",
        "# Calculate the number of checkboxes per column\n",
        "checkboxes_per_column = (len(checkboxes) + 2) // 3\n",
        "checkboxes_per_column_r = (len(checkboxes_r) + 2) // 3\n",
        "checkboxes_per_column_a = (len(checkboxes_a) + 2) // 3\n",
        "checkboxes_per_column_m = (len(checkboxes_m) + 2) // 3\n",
        "checkboxes_per_column_x = (len(checkboxes_x) + 2) // 3\n",
        "checkboxes_per_column_d = (len(checkboxes_d) + 2) // 3\n",
        "\n",
        "# Split the checkboxes into 3 equally divided columns\n",
        "columns = [widgets.VBox(children=checkboxes[i:i+checkboxes_per_column]) for i in range(0, len(checkboxes), checkboxes_per_column)]\n",
        "columns_r = [widgets.VBox(children=checkboxes_r[i:i+checkboxes_per_column_r]) for i in range(0, len(checkboxes_r), checkboxes_per_column_r)]\n",
        "columns_a = [widgets.VBox(children=checkboxes_a[i:i+checkboxes_per_column_a]) for i in range(0, len(checkboxes_a), checkboxes_per_column_a)]\n",
        "columns_m = [widgets.VBox(children=checkboxes_m[i:i+checkboxes_per_column_m]) for i in range(0, len(checkboxes_m), checkboxes_per_column_m)]\n",
        "columns_x = [widgets.VBox(children=checkboxes_x[i:i+checkboxes_per_column_x]) for i in range(0, len(checkboxes_x), checkboxes_per_column_x)]\n",
        "columns_d = [widgets.VBox(children=checkboxes_d[i:i+checkboxes_per_column_d]) for i in range(0, len(checkboxes_d), checkboxes_per_column_d)]\n",
        "\n",
        "# Create a download button\n",
        "download_button = widgets.Button(description=\"Download\")\n",
        "\n",
        "def downloadModel(url, model_name, vae):\n",
        "        print(f'⏳ Downloading {model_name} models ...')\n",
        "        if vae == 'N/A':\n",
        "          if 'huggingface.co' in url:\n",
        "              filename = url.split('/')[-1]\n",
        "              !aria2c --console-log-level=error -c -q -x 16 -s 16 -k 1M {url} -o {filename} -d /content/CodeUI/models/checkpoints\n",
        "          else:\n",
        "              !aria2c --console-log-level=error -c -q -x 16 -s 16 -k 1M {url} -d /content/CodeUI/models/checkpoints\n",
        "\n",
        "        elif 'VAE' in vae:\n",
        "\n",
        "          if 'huggingface.co' in url:\n",
        "              filename = url.split('/')[-1]\n",
        "              !aria2c --console-log-level=error -c -q -x 16 -s 16 -k 1M {url} -o {filename} -d /content/CodeUI/models/checkpoints\n",
        "              !aria2c --console-log-level=error -c -q -x 16 -s 16 -k 1M {vae} -o {filename} -d /content/CodeUI/models/VAE\n",
        "          else:\n",
        "              !aria2c --console-log-level=error -c -q -x 16 -s 16 -k 1M {url} -d /content/CodeUI/models/checkpoints\n",
        "              !aria2c --console-log-level=error -c -q -x 16 -s 16 -k 1M {vae} -d /content/CodeUI/models/VAE\n",
        "\n",
        "        else:\n",
        "\n",
        "          if 'huggingface.co' in url:\n",
        "              filename = url.split('/')[-1]\n",
        "              !aria2c --console-log-level=error -c -q -x 16 -s 16 -k 1M {url} -o {filename} -d /content/CodeUI/models/Stable-diffusion\n",
        "              !aria2c --console-log-level=error -c -q -x 16 -s 16 -k 1M {vae} -o {filename} -d /content/CodeUI/configs\n",
        "\n",
        "          else:\n",
        "              !aria2c --console-log-level=error -c -q -x 16 -s 16 -k 1M {url} -d /content/CodeUI/models/Stable-diffusion\n",
        "              !aria2c --console-log-level=error -c -q -x 16 -s 16 -k 1M {vae} -d /content/CodeUI/configs\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def download_checked_items(button):\n",
        "    checked_items = [(model_urls[i], model_names[i], vae_models[i]) for i in range(len(checkboxes)) if checkboxes[i].value]\n",
        "    checked_items_r =[(model_urls_r[i], r_model_names[i], vae_models_r[i]) for i in range(len(checkboxes_r)) if checkboxes_r[i].value]\n",
        "    checked_items_a =[(model_urls_a[i], a_model_names[i], vae_models_a[i]) for i in range(len(checkboxes_a)) if checkboxes_a[i].value]\n",
        "    checked_items_m =[(model_urls_m[i], m_model_names[i], vae_models_m[i]) for i in range(len(checkboxes_m)) if checkboxes_m[i].value]\n",
        "    checked_items_x =[(model_urls_x[i], x_model_names[i], vae_models_x[i]) for i in range(len(checkboxes_x)) if checkboxes_x[i].value]\n",
        "    checked_items_d =[(model_urls_d[i], d_model_names[i], vae_models_d[i]) for i in range(len(checkboxes_d)) if checkboxes_d[i].value]\n",
        "\n",
        "    #checked_model_names2 = [model_names2[i] for i in range(len(checkboxes2)) if checkboxes2[i].value]\n",
        "    #checked_trigger = [lora_trigger[i] for i in range(len(checkboxes2)) if checkboxes2[i].value]\n",
        "    %cd /content/\n",
        "    clear_output(wait=True)\n",
        "    # Download the models in \"Stable-diffusion\"\n",
        "    for url, model_name, vae in checked_items:\n",
        "        downloadModel(url, model_name, vae)\n",
        "    for url, model_name, vae in checked_items_r:\n",
        "        downloadModel(url, model_name, vae)\n",
        "    for url, model_name, vae in checked_items_a:\n",
        "        downloadModel(url, model_name, vae)\n",
        "    for url, model_name, vae in checked_items_m:\n",
        "        downloadModel(url, model_name, vae)\n",
        "    for url, model_name, vae in checked_items_x:\n",
        "        downloadModel(url, model_name, vae)\n",
        "    for url, model_name, vae in checked_items_d:\n",
        "        downloadModel(url, model_name, vae)\n",
        "   #clear_output(wait=True)\n",
        "    print('All selected models downloaded successfully.')\n",
        "\n",
        "# Attach the download function to the button click event\n",
        "download_button.on_click(download_checked_items)\n",
        "\n",
        "# Display the checkbox list in 3 columns\n",
        "widgets.HBox(children=columns)\n",
        "widgets.HBox(children=columns_r)\n",
        "widgets.HBox(children=columns_a)\n",
        "widgets.HBox(children=columns_m)\n",
        "widgets.HBox(children=columns_x)\n",
        "widgets.HBox(children=columns_d)\n",
        "\n",
        "# Create a layout with the checkboxes and the download button\n",
        "layout = widgets.HBox(children=columns)\n",
        "ckpt_r = widgets.HBox(children=columns_r)\n",
        "ckpt_a = widgets.HBox(children=columns_a)\n",
        "ckpt_m = widgets.HBox(children=columns_m)\n",
        "ckpt_x = widgets.HBox(children=columns_x)\n",
        "ckpt_d = widgets.HBox(children=columns_d)\n",
        "\n",
        "\n",
        "#Select All\n",
        "check_all_button = widgets.Button(description=\"Check All\")\n",
        "check_all_state = True\n",
        "\n",
        "def toggle_check_all(button):\n",
        "    global check_all_state\n",
        "    if check_all_state:\n",
        "        button.description = \"Uncheck All\"\n",
        "        for checkbox in checkboxes:\n",
        "            checkbox.value = True\n",
        "        for checkbox in checkboxes_r:\n",
        "            checkbox.value = True\n",
        "        for checkbox in checkboxes_a:\n",
        "            checkbox.value = True\n",
        "        for checkbox in checkboxes_m:\n",
        "            checkbox.value = True\n",
        "        for checkbox in checkboxes_x:\n",
        "            checkbox.value = True\n",
        "        for checkbox in checkboxes_d:\n",
        "            checkbox.value = True\n",
        "\n",
        "    else:\n",
        "        button.description = \"Check All\"\n",
        "        for checkbox in checkboxes:\n",
        "            checkbox.value = False\n",
        "        for checkbox in checkboxes_r:\n",
        "            checkbox.value = False\n",
        "        for checkbox in checkboxes_a:\n",
        "            checkbox.value = False\n",
        "        for checkbox in checkboxes_m:\n",
        "            checkbox.value = False\n",
        "        for checkbox in checkboxes_x:\n",
        "            checkbox.value = False\n",
        "        for checkbox in checkboxes_d:\n",
        "            checkbox.value = True\n",
        "\n",
        "    check_all_state = not check_all_state\n",
        "\n",
        "\n",
        "check_all_button.on_click(toggle_check_all)\n",
        "\n",
        "\n",
        "check_all_button_chpt = widgets.Button(description=\"Check All\")\n",
        "check_all_state = True\n",
        "\n",
        "\n",
        "# Display the layout\n",
        "#display(HTML(\"<h3>Checkpoint<h3>\"))\n",
        "#display(layout)\n",
        "#display(HTML(\"<h4><u>Realistic Model</u><h4>\"))\n",
        "#display(ckpt_r)\n",
        "#display(HTML(\"<hr>\"))\n",
        "#display(HTML(\"<h4><u>Anime Base Model</u><h4>\"))\n",
        "#display(ckpt_a)\n",
        "#display(HTML(\"<hr>\"))\n",
        "#display(HTML(\"<h4><u>Real + Anime Mix Model</u><h4>\"))\n",
        "#display(ckpt_m)\n",
        "#display(HTML(\"<hr>\"))\n",
        "#display(HTML(\"<h4><u>2.5D</u><h4>\"))\n",
        "#display(ckpt_d)\n",
        "#display(HTML(\"<hr>\"))\n",
        "#display(HTML(\"<h4><u>Adult</u><h4>\"))\n",
        "#display(ckpt_x)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from ipywidgets import Button, HBox, VBox, Output\n",
        "from IPython.display import display, clear_output\n",
        "\n",
        "words = ['Realistic Model', 'Anime Base Model', 'Real + Anime Mix Model', '2.5D', 'Adult']\n",
        "#items = [Button(description=w) for w in words]\n",
        "#left_box = VBox([items[0], items[1]])\n",
        "#right_box = VBox([items[2], items[3], items[4]])\n",
        "output = Output()\n",
        "\n",
        "\n",
        "# define the number of buttons to display in each column\n",
        "#buttons_per_column = len(words) +2 // 3\n",
        "\n",
        "# create the buttons and divide them into two columns\n",
        "items = [Button(description=w, layout={'width': 'auto'}) for w in words]\n",
        "button_box = HBox(items)\n",
        "\n",
        "\n",
        "# define callback function to print message\n",
        "def on_button_clicked(button):\n",
        "    with output:\n",
        "        if button.description == \"Realistic Model\":\n",
        "            clear_output(wait=True)\n",
        "            display(ckpt_r)\n",
        "\n",
        "        elif button.description == \"Anime Base Model\":\n",
        "            clear_output(wait=True)\n",
        "            display(ckpt_a)\n",
        "\n",
        "        elif button.description == \"Real + Anime Mix Model\":\n",
        "            clear_output(wait=True)\n",
        "            display(ckpt_m)\n",
        "\n",
        "        elif button.description == \"2.5D\":\n",
        "            clear_output(wait=True)\n",
        "            display(ckpt_d)\n",
        "\n",
        "        else :\n",
        "            clear_output(wait=True)\n",
        "            display(ckpt_x)\n",
        "\n",
        "# add callback to each button\n",
        "for button in items:\n",
        "    button.on_click(on_button_clicked)\n",
        "\n",
        "#display(HBox([left_box, right_box,]))\n",
        "display(button_box )\n",
        "display(output)\n",
        "display(HTML(\"<hr>\"))\n",
        "display(check_all_button)\n",
        "display(download_button)\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "H5C_5ZrD4U6Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#VAE\n",
        "!wget -c https://huggingface.co/stabilityai/sd-vae-ft-mse-original/resolve/main/vae-ft-mse-840000-ema-pruned.safetensors -P ./models/vae/\n"
      ],
      "metadata": {
        "id": "WK2DazszV05V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Install Manager\n",
        "%cd /content/CodeUI/custom_nodes\n",
        "!git clone https://github.com/ltdrdata/ComfyUI-Manager.git\n",
        "%cd /content/CodeUI"
      ],
      "metadata": {
        "id": "XEvmdZwBS429"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dddddddddd"
      },
      "outputs": [],
      "source": [
        "# Checkpoints\n",
        "\n",
        "### SDXL\n",
        "### I recommend these workflow examples: https://comfyanonymous.github.io/ComfyUI_examples/sdxl/\n",
        "\n",
        "!wget -c https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_base_1.0.safetensors -P ./models/checkpoints/\n",
        "!wget -c https://huggingface.co/stabilityai/stable-diffusion-xl-refiner-1.0/resolve/main/sd_xl_refiner_1.0.safetensors -P ./models/checkpoints/\n",
        "\n",
        "# SDXL ReVision\n",
        "!wget -c https://huggingface.co/comfyanonymous/clip_vision_g/resolve/main/clip_vision_g.safetensors -P ./models/clip_vision/\n",
        "\n",
        "# SD1.5\n",
        "!wget -c https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.ckpt -P ./models/checkpoints/\n",
        "\n",
        "# SD2\n",
        "!wget -c https://huggingface.co/stabilityai/stable-diffusion-2-1-base/resolve/main/v2-1_512-ema-pruned.safetensors -P ./models/checkpoints/\n",
        "!wget -c https://huggingface.co/stabilityai/stable-diffusion-2-1/resolve/main/v2-1_768-ema-pruned.safetensors -P ./models/checkpoints/\n",
        "\n",
        "# Some SD1.5 anime style\n",
        "!wget -c https://huggingface.co/WarriorMama777/OrangeMixs/resolve/main/Models/AbyssOrangeMix2/AbyssOrangeMix2_hard.safetensors -P ./models/checkpoints/\n",
        "!wget -c https://huggingface.co/WarriorMama777/OrangeMixs/resolve/main/Models/AbyssOrangeMix3/AOM3A1_orangemixs.safetensors -P ./models/checkpoints/\n",
        "!wget -c https://huggingface.co/WarriorMama777/OrangeMixs/resolve/main/Models/AbyssOrangeMix3/AOM3A3_orangemixs.safetensors -P ./models/checkpoints/\n",
        "!wget -c https://huggingface.co/Linaqruf/anything-v3.0/resolve/main/anything-v3-fp16-pruned.safetensors -P ./models/checkpoints/\n",
        "\n",
        "# Waifu Diffusion 1.5 (anime style SD2.x 768-v)\n",
        "!wget -c https://huggingface.co/waifu-diffusion/wd-1-5-beta3/resolve/main/wd-illusion-fp16.safetensors -P ./models/checkpoints/\n",
        "\n",
        "\n",
        "# unCLIP models\n",
        "!wget -c https://huggingface.co/comfyanonymous/illuminatiDiffusionV1_v11_unCLIP/resolve/main/illuminatiDiffusionV1_v11-unclip-h-fp16.safetensors -P ./models/checkpoints/\n",
        "!wget -c https://huggingface.co/comfyanonymous/wd-1.5-beta2_unCLIP/resolve/main/wd-1-5-beta2-aesthetic-unclip-h-fp16.safetensors -P ./models/checkpoints/\n",
        "\n",
        "\n",
        "# VAE\n",
        "!wget -c https://huggingface.co/stabilityai/sd-vae-ft-mse-original/resolve/main/vae-ft-mse-840000-ema-pruned.safetensors -P ./models/vae/\n",
        "!wget -c https://huggingface.co/WarriorMama777/OrangeMixs/resolve/main/VAEs/orangemix.vae.pt -P ./models/vae/\n",
        "!wget -c https://huggingface.co/hakurei/waifu-diffusion-v1-4/resolve/main/vae/kl-f8-anime2.ckpt -P ./models/vae/\n",
        "\n",
        "\n",
        "# Loras\n",
        "!wget -c https://civitai.com/api/download/models/10350 -O ./models/loras/theovercomer8sContrastFix_sd21768.safetensors #theovercomer8sContrastFix SD2.x 768-v\n",
        "!wget -c https://civitai.com/api/download/models/10638 -O ./models/loras/theovercomer8sContrastFix_sd15.safetensors #theovercomer8sContrastFix SD1.x\n",
        "!wget -c https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_offset_example-lora_1.0.safetensors -P ./models/loras/ #SDXL offset noise lora\n",
        "\n",
        "\n",
        "# T2I-Adapter\n",
        "!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_depth_sd14v1.pth -P ./models/controlnet/\n",
        "!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_seg_sd14v1.pth -P ./models/controlnet/\n",
        "!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_sketch_sd14v1.pth -P ./models/controlnet/\n",
        "!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_keypose_sd14v1.pth -P ./models/controlnet/\n",
        "!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_openpose_sd14v1.pth -P ./models/controlnet/\n",
        "!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_color_sd14v1.pth -P ./models/controlnet/\n",
        "!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_canny_sd14v1.pth -P ./models/controlnet/\n",
        "\n",
        "# T2I Styles Model\n",
        "!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_style_sd14v1.pth -P ./models/style_models/\n",
        "\n",
        "# CLIPVision model (needed for styles model)\n",
        "!wget -c https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/pytorch_model.bin -O ./models/clip_vision/clip_vit14.bin\n",
        "\n",
        "\n",
        "# ControlNet\n",
        "!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11e_sd15_ip2p_fp16.safetensors -P ./models/controlnet/\n",
        "!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11e_sd15_shuffle_fp16.safetensors -P ./models/controlnet/\n",
        "!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_canny_fp16.safetensors -P ./models/controlnet/\n",
        "!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11f1p_sd15_depth_fp16.safetensors -P ./models/controlnet/\n",
        "!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_inpaint_fp16.safetensors -P ./models/controlnet/\n",
        "!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_lineart_fp16.safetensors -P ./models/controlnet/\n",
        "!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_mlsd_fp16.safetensors -P ./models/controlnet/\n",
        "!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_normalbae_fp16.safetensors -P ./models/controlnet/\n",
        "!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_openpose_fp16.safetensors -P ./models/controlnet/\n",
        "!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_scribble_fp16.safetensors -P ./models/controlnet/\n",
        "!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_seg_fp16.safetensors -P ./models/controlnet/\n",
        "!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_softedge_fp16.safetensors -P ./models/controlnet/\n",
        "!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15s2_lineart_anime_fp16.safetensors -P ./models/controlnet/\n",
        "!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11u_sd15_tile_fp16.safetensors -P ./models/controlnet/\n",
        "\n",
        "# ControlNet SDXL\n",
        "!wget -c https://huggingface.co/stabilityai/control-lora/resolve/main/control-LoRAs-rank256/control-lora-canny-rank256.safetensors -P ./models/controlnet/\n",
        "!wget -c https://huggingface.co/stabilityai/control-lora/resolve/main/control-LoRAs-rank256/control-lora-depth-rank256.safetensors -P ./models/controlnet/\n",
        "!wget -c https://huggingface.co/stabilityai/control-lora/resolve/main/control-LoRAs-rank256/control-lora-recolor-rank256.safetensors -P ./models/controlnet/\n",
        "!wget -c https://huggingface.co/stabilityai/control-lora/resolve/main/control-LoRAs-rank256/control-lora-sketch-rank256.safetensors -P ./models/controlnet/\n",
        "\n",
        "# Controlnet Preprocessor nodes by Fannovel16\n",
        "!cd custom_nodes && git clone https://github.com/Fannovel16/comfy_controlnet_preprocessors; cd comfy_controlnet_preprocessors && python install.py\n",
        "\n",
        "\n",
        "# GLIGEN\n",
        "!wget -c https://huggingface.co/comfyanonymous/GLIGEN_pruned_safetensors/resolve/main/gligen_sd14_textbox_pruned_fp16.safetensors -P ./models/gligen/\n",
        "\n",
        "\n",
        "# ESRGAN upscale model\n",
        "!wget -c https://github.com/xinntao/Real-ESRGAN/releases/download/v0.1.0/RealESRGAN_x4plus.pth -P ./models/upscale_models/\n",
        "!wget -c https://huggingface.co/sberbank-ai/Real-ESRGAN/resolve/main/RealESRGAN_x2.pth -P ./models/upscale_models/\n",
        "!wget -c https://huggingface.co/sberbank-ai/Real-ESRGAN/resolve/main/RealESRGAN_x4.pth -P ./models/upscale_models/\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkkkkkkkkkkkkkk"
      },
      "source": [
        "### Run ComfyUI with cloudflared (Recommended Way)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fastai torch==2.1.0\n",
        "!pip install torchaudio==2.1.0 torchdata==2.1.0 torchtext==2.1.0"
      ],
      "metadata": {
        "id": "LnzD4k_RsOmj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jjjjjjjjjjjjjj",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Can't Use for free user\n",
        "!wget https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb\n",
        "!dpkg -i cloudflared-linux-amd64.deb\n",
        "\n",
        "import subprocess\n",
        "import threading\n",
        "import time\n",
        "import socket\n",
        "import urllib.request\n",
        "\n",
        "def iframe_thread(port):\n",
        "  while True:\n",
        "      time.sleep(0.5)\n",
        "      sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "      result = sock.connect_ex(('127.0.0.1', port))\n",
        "      if result == 0:\n",
        "        break\n",
        "      sock.close()\n",
        "  print(\"\\nCodeUI finished loading, trying to launch cloudflared (if it gets stuck here cloudflared is having issues)\\n\")\n",
        "\n",
        "  p = subprocess.Popen([\"cloudflared\", \"tunnel\", \"--url\", \"http://127.0.0.1:{}\".format(port)], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "  for line in p.stderr:\n",
        "    l = line.decode()\n",
        "    if \"trycloudflare.com \" in l:\n",
        "      print(\"This is the URL to access CodeUI:\", l[l.find(\"http\"):], end='')\n",
        "    #print(l, end='')\n",
        "\n",
        "\n",
        "threading.Thread(target=iframe_thread, daemon=True, args=(1233,)).start()\n",
        "\n",
        "!python main.py --dont-print-server"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkkkkkkkkkkkkk"
      },
      "source": [
        "### Run ComfyUI with localtunnel\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "jjjjjjjjjjjjj",
        "outputId": "b6aff733-a6bc-411e-c473-366ab3b5b286",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shell-init: error retrieving current directory: getcwd: cannot access parent directories: Transport endpoint is not connected\n",
            "Error: ENOTCONN: socket is not connected, uv_cwd\n",
            "    at process.wrappedCwd (internal/bootstrap/switches/does_own_process_state.js:129:28)\n",
            "    at process.cwd (/tools/node/lib/node_modules/npm/node_modules/graceful-fs/polyfills.js:10:19)\n",
            "    at Conf.loadPrefix (/tools/node/lib/node_modules/npm/lib/config/load-prefix.js:46:24)\n",
            "    at load_ (/tools/node/lib/node_modules/npm/lib/config/core.js:109:8)\n",
            "    at Conf.<anonymous> (/tools/node/lib/node_modules/npm/lib/config/core.js:96:5)\n",
            "    at Conf.emit (events.js:315:20)\n",
            "    at ConfigChain._resolve (/tools/node/lib/node_modules/npm/node_modules/config-chain/index.js:281:34)\n",
            "    at ConfigChain.add (/tools/node/lib/node_modules/npm/node_modules/config-chain/index.js:259:10)\n",
            "    at Conf.add (/tools/node/lib/node_modules/npm/lib/config/core.js:338:27)\n",
            "    at ConfigChain.addString (/tools/node/lib/node_modules/npm/node_modules/config-chain/index.js:244:8)\n",
            "internal/bootstrap/switches/does_own_process_state.js:129\n",
            "    cachedCwd = rawMethods.cwd();\n",
            "                           ^\n",
            "\n",
            "Error: ENOTCONN: socket is not connected, uv_cwd\n",
            "\u001b[90m    at process.wrappedCwd (internal/bootstrap/switches/does_own_process_state.js:129:28)\u001b[39m\n",
            "    at process.cwd (/tools/node/lib/node_modules/\u001b[4mnpm\u001b[24m/node_modules/\u001b[4mgraceful-fs\u001b[24m/polyfills.js:10:19)\n",
            "    at process.errorHandler (/tools/node/lib/node_modules/\u001b[4mnpm\u001b[24m/lib/utils/error-handler.js:183:30)\n",
            "\u001b[90m    at process.emit (events.js:315:20)\u001b[39m\n",
            "\u001b[90m    at process._fatalException (internal/process/execution.js:163:25)\u001b[39m {\n",
            "  errno: \u001b[33m-107\u001b[39m,\n",
            "  code: \u001b[32m'ENOTCONN'\u001b[39m,\n",
            "  syscall: \u001b[32m'uv_cwd'\u001b[39m\n",
            "}\n",
            "shell-init: error retrieving current directory: getcwd: cannot access parent directories: Transport endpoint is not connected\n",
            "shell-init: error retrieving current directory: getcwd: cannot access parent directories: Transport endpoint is not connected\n",
            "python3: can't open file 'main.py': [Errno 107] Transport endpoint is not connected\n"
          ]
        }
      ],
      "source": [
        "#@title Can't Use for free user\n",
        "!npm install -g localtunnel\n",
        "\n",
        "import subprocess\n",
        "import threading\n",
        "import time\n",
        "import socket\n",
        "import urllib.request\n",
        "\n",
        "def iframe_thread(port):\n",
        "  while True:\n",
        "      time.sleep(0.5)\n",
        "      sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "      result = sock.connect_ex(('127.0.0.1', port))\n",
        "      if result == 0:\n",
        "        break\n",
        "      sock.close()\n",
        "  print(\"\\nComUI finished loading, trying to launch localtunnel (if it gets stuck here localtunnel is having issues)\\n\")\n",
        "\n",
        "  print(\"The password/enpoint ip for localtunnel is:\", urllib.request.urlopen('https://ipv4.icanhazip.com').read().decode('utf8').strip(\"\\n\"))\n",
        "  p = subprocess.Popen([\"lt\", \"--port\", \"{}\".format(port)], stdout=subprocess.PIPE)\n",
        "  for line in p.stdout:\n",
        "    print(line.decode(), end='')\n",
        "\n",
        "\n",
        "threading.Thread(target=iframe_thread, daemon=True, args=(1233,)).start()\n",
        "\n",
        "!python main.py --dont-print-server"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall torch torchvision\n"
      ],
      "metadata": {
        "id": "hwuHJBiOpwLo",
        "outputId": "ba7ad3e0-8084-496e-af58-89a620472bef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch 2.0.1\n",
            "Uninstalling torch-2.0.1:\n",
            "  Would remove:\n",
            "    /usr/local/bin/convert-caffe2-to-onnx\n",
            "    /usr/local/bin/convert-onnx-to-caffe2\n",
            "    /usr/local/bin/torchrun\n",
            "    /usr/local/lib/python3.10/dist-packages/functorch/*\n",
            "    /usr/local/lib/python3.10/dist-packages/nvfuser/*\n",
            "    /usr/local/lib/python3.10/dist-packages/torch-2.0.1.dist-info/*\n",
            "    /usr/local/lib/python3.10/dist-packages/torch/*\n",
            "    /usr/local/lib/python3.10/dist-packages/torchgen/*\n",
            "Proceed (Y/n)? y\n",
            "  Successfully uninstalled torch-2.0.1\n",
            "Found existing installation: torchvision 0.15.2+cu118\n",
            "Uninstalling torchvision-0.15.2+cu118:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.10/dist-packages/torchvision-0.15.2+cu118.dist-info/*\n",
            "    /usr/local/lib/python3.10/dist-packages/torchvision.libs/libcudart.60cfec8e.so.11.0\n",
            "    /usr/local/lib/python3.10/dist-packages/torchvision.libs/libjpeg.ceea7512.so.62\n",
            "    /usr/local/lib/python3.10/dist-packages/torchvision.libs/libnvjpeg.70530407.so.11\n",
            "    /usr/local/lib/python3.10/dist-packages/torchvision.libs/libpng16.7f72a3c5.so.16\n",
            "    /usr/local/lib/python3.10/dist-packages/torchvision.libs/libz.e3d3156c.so.1\n",
            "    /usr/local/lib/python3.10/dist-packages/torchvision/*\n",
            "Proceed (Y/n)? y\n",
            "  Successfully uninstalled torchvision-0.15.2+cu118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
      ],
      "metadata": {
        "id": "Gb9M_TT-pUR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchvision\n"
      ],
      "metadata": {
        "id": "2tGwxFiQqFwJ",
        "outputId": "682e9a8c-e9e8-4ecf-f07e-75dc1736800f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchvision\n",
            "  Downloading torchvision-0.16.0-cp310-cp310-manylinux1_x86_64.whl (6.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
            "Collecting torch==2.1.0 (from torchvision)\n",
            "  Downloading torch-2.1.0-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.1.0->torchvision)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.1.0->torchvision)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.1.0->torchvision)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m93.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.1.0->torchvision)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.1.0->torchvision)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.1.0->torchvision)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch==2.1.0->torchvision)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.1.0->torchvision)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.1.0->torchvision)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.18.1 (from torch==2.1.0->torchvision)\n",
            "  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch==2.1.0->torchvision)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==2.1.0 (from torch==2.1.0->torchvision)\n",
            "  Downloading triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.0->torchvision)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.2.140-py3-none-manylinux1_x86_64.whl (20.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.2/20.2 MB\u001b[0m \u001b[31m77.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.0->torchvision) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.0->torchvision) (1.3.0)\n",
            "Installing collected packages: triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.0.0\n",
            "    Uninstalling triton-2.0.0:\n",
            "      Successfully uninstalled triton-2.0.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "fastai 2.7.12 requires torch<2.1,>=1.7, but you have torch 2.1.0 which is incompatible.\n",
            "torchaudio 2.0.2+cu118 requires torch==2.0.1, but you have torch 2.1.0 which is incompatible.\n",
            "torchdata 0.6.1 requires torch==2.0.1, but you have torch 2.1.0 which is incompatible.\n",
            "torchtext 0.15.2 requires torch==2.0.1, but you have torch 2.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvjitlink-cu12-12.2.140 nvidia-nvtx-cu12-12.1.105 torch-2.1.0 torchvision-0.16.0 triton-2.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fastai torch==2.1.0\n",
        "!pip install torchaudio==2.1.0 torchdata==2.1.0 torchtext==2.1.0\n"
      ],
      "metadata": {
        "id": "xUQ64hf9rlAS",
        "outputId": "8d0c4261-cdca-4b44-fc89-bc26c90b9867",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shell-init: error retrieving current directory: getcwd: cannot access parent directories: Transport endpoint is not connected\n",
            "shell-init: error retrieving current directory: getcwd: cannot access parent directories: Transport endpoint is not connected\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 5, in <module>\n",
            "    from pip._internal.cli.main import main\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/main.py\", line 10, in <module>\n",
            "    from pip._internal.cli.autocompletion import autocomplete\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/autocompletion.py\", line 10, in <module>\n",
            "    from pip._internal.cli.main_parser import create_main_parser\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/main_parser.py\", line 9, in <module>\n",
            "    from pip._internal.build_env import get_runnable_pip\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/build_env.py\", line 19, in <module>\n",
            "    from pip._internal.cli.spinners import open_spinner\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/spinners.py\", line 9, in <module>\n",
            "    from pip._internal.utils.logging import get_indentation\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/logging.py\", line 13, in <module>\n",
            "    from pip._vendor.rich.console import (\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/rich/__init__.py\", line 17, in <module>\n",
            "    _IMPORT_CWD = os.path.abspath(os.getcwd())\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "shell-init: error retrieving current directory: getcwd: cannot access parent directories: Transport endpoint is not connected\n",
            "shell-init: error retrieving current directory: getcwd: cannot access parent directories: Transport endpoint is not connected\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 5, in <module>\n",
            "    from pip._internal.cli.main import main\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/main.py\", line 10, in <module>\n",
            "    from pip._internal.cli.autocompletion import autocomplete\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/autocompletion.py\", line 10, in <module>\n",
            "    from pip._internal.cli.main_parser import create_main_parser\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/main_parser.py\", line 9, in <module>\n",
            "    from pip._internal.build_env import get_runnable_pip\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/build_env.py\", line 19, in <module>\n",
            "    from pip._internal.cli.spinners import open_spinner\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/spinners.py\", line 9, in <module>\n",
            "    from pip._internal.utils.logging import get_indentation\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/logging.py\", line 13, in <module>\n",
            "    from pip._vendor.rich.console import (\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/rich/__init__.py\", line 17, in <module>\n",
            "    _IMPORT_CWD = os.path.abspath(os.getcwd())\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "JnxX0pNfx0f-",
        "outputId": "e8b62f85-4fce-4aab-f8f6-ac3c16ab2c09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cloudflared-linux-amd64.deb    comfyui.prev.log\t\t       models\n",
            "cloudflared-linux-amd64.deb.1  comfyui_screenshot.png\t       nodes.py\n",
            "cloudflared-linux-amd64.deb.2  cuda_malloc.py\t\t       nohup.out\n",
            "cloudflared-linux-amd64.deb.3  custom_nodes\t\t       notebooks\n",
            "cloudflared-linux-amd64.deb.4  custom_nodes_old\t\t       output\n",
            "cloudflared-linux-amd64.deb.5  custom_nodes_old2\t       output.log\n",
            "cloudflared-linux-amd64.deb.6  downloader.ipynb\t\t       plugin-for-SD\n",
            "cloudflared-linux-amd64.deb.7  downloaderV1.ipynb\t       __pycache__\n",
            "cloudflared-linux-amd64.deb.8  downloaderV2.ipynb\t       README.md\n",
            "CODEOWNERS\t\t       execution.py\t\t       requirements.txt\n",
            "comfy\t\t\t       extra_model_paths.yaml.example  script_examples\n",
            "comfy_extras\t\t       folder_paths.py\t\t       server.py\n",
            "comfyui_colab_V2.ipynb\t       input\t\t\t       styles\n",
            "comfyui.log\t\t       latent_preview.py\t       web\n",
            "ComfyUI-Manager\t\t       LICENSE\n",
            "comfyui.prev2.log\t       main.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "import urllib.request\n",
        "import subprocess\n",
        "\n",
        "def iframe_thread(port):\n",
        "    result = 1\n",
        "    while result != 0:\n",
        "        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "        result = sock.connect_ex(('127.0.0.1', port))\n",
        "        if result == 0:\n",
        "            break\n",
        "        sock.close()\n",
        "    print(\"\\nComUI finished loading, trying to launch localtunnel (if it gets stuck here localtunnel is having issues)\\n\")\n",
        "\n",
        "    external_ip = urllib.request.urlopen('https://ipv4.icanhazip.com').read().decode('utf8').strip(\"\\n\")\n",
        "    print(\"The password/endpoint IP for localtunnel is:\", external_ip)\n",
        "\n",
        "    p = subprocess.Popen([\"lt\", \"--port\", \"{}\".format(port)], stdout=subprocess.PIPE)\n",
        "    for line in p.stdout:\n",
        "        print(line.decode(), end='')\n",
        "\n",
        "    p.wait()  # Wait for the lt command to complete\n",
        "\n",
        "threading.Thread(target=iframe_thread, daemon=True, args=(1233,)).start()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgWerz6aZCt2",
        "outputId": "dc7984c1-a08b-4dcc-bbb2-c839fd9433d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ComUI finished loading, trying to launch localtunnel (if it gets stuck here localtunnel is having issues)\n",
            "\n",
            "The password/endpoint IP for localtunnel is: 34.125.168.61\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!lt --port 1233"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLR0E6_NZqpO",
        "outputId": "25f10bef-b235-44fb-92b3-9807edf47894"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "your url is: https://slick-monkeys-visit.loca.lt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/monsterhunters/plugin-for-SD.git"
      ],
      "metadata": {
        "id": "V2HRtYW07XlX",
        "outputId": "8580a965-b7f2-4002-84cf-a21e50cd1b4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'plugin-for-SD'...\n",
            "remote: Enumerating objects: 130, done.\u001b[K\n",
            "remote: Counting objects: 100% (56/56), done.\u001b[K\n",
            "remote: Compressing objects: 100% (48/48), done.\u001b[K\n",
            "remote: Total 130 (delta 8), reused 55 (delta 8), pack-reused 74\u001b[K\n",
            "Receiving objects: 100% (130/130), 4.09 MiB | 6.97 MiB/s, done.\n",
            "Resolving deltas: 100% (18/18), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gggggggggg"
      },
      "source": [
        "### Run ComfyUI with colab iframe (use only in case the previous way with localtunnel doesn't work)\n",
        "\n",
        "You should see the ui appear in an iframe. If you get a 403 error, it's your firefox settings or an extension that's messing things up.\n",
        "\n",
        "If you want to open it in another window use the link.\n",
        "\n",
        "Note that some UI features like live image previews won't work because the colab iframe blocks websockets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hhhhhhhhhh"
      },
      "outputs": [],
      "source": [
        "import threading\n",
        "import time\n",
        "import socket\n",
        "def iframe_thread(port):\n",
        "  while True:\n",
        "      time.sleep(0.5)\n",
        "      sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "      result = sock.connect_ex(('127.0.0.1', port))\n",
        "      if result == 0:\n",
        "        break\n",
        "      sock.close()\n",
        "  from google.colab import output\n",
        "  output.serve_kernel_port_as_iframe(port, height=1024)\n",
        "  print(\"to open it in a window you can open this link here:\")\n",
        "  output.serve_kernel_port_as_window(port)\n",
        "\n",
        "threading.Thread(target=iframe_thread, daemon=True, args=(1233,)).start()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " !nohup script -c \"python main.py --dont-print-server\" output.log &\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJ2S1ZpkXIC2",
        "outputId": "4faedf4b-1673-4452-b3a4-171b7a2cc8ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nohup: appending output to 'nohup.out'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --dont-print-server"
      ],
      "metadata": {
        "id": "PkL8Nl_QXn0u"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}